{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SpectralClustering and DBSCAN with minHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.sparse import csr_matrix\n",
    "import hashlib\n",
    "from random import randint\n",
    "\n",
    "sparsity_factor = 0.1\n",
    "samples = 3000\n",
    "features = 1000\n",
    "classes = 2\n",
    "clusters_per_class = 2\n",
    "scale_ = 1.0\n",
    "data_dense, y_true = make_classification(n_samples=samples, n_features=features, n_informative=2, \n",
    "                                 n_redundant=2, n_repeated=0, n_classes=classes, \n",
    "                                 n_clusters_per_class=clusters_per_class, weights=None, flip_y=0.01,\n",
    "                                 class_sep=1.0, hypercube=True, shift=0.0, scale=scale_,\n",
    "                                 shuffle=True, random_state=None)\n",
    "instances_list = []\n",
    "features_list = []\n",
    "data_list = []\n",
    "for i in xrange(len(data_dense)):\n",
    "    for j in xrange(len(data_dense[i])):\n",
    "        instances_list.append(i)\n",
    "        features_list.append(hash(str(data_dense[i][j])[0:4]+str(j)) % (features/sparsity_factor))\n",
    "        data_list.append(data_dense[i][j])\n",
    "data_sparse = csr_matrix((data_list, (instances_list, features_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "SpectralClustering :\t-0.0 \t\tComputation time:  18.1502420902\n",
      "MinHashSpectralClustering :\t0.0 \t\tComputation time:  16.2415990829\n",
      "DBSCAN :\t0.0 \t\tComputation time:  6.18379712105\n",
      "MinHashDBSCAN :\t0.0 \t\tComputation time:  2.189920187\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print(__doc__)\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "from neighborsMinHash.clustering import MinHashClustering \n",
    "# from neighborsMinHash.clustering import MinHashDBSCAN\n",
    "from neighborsMinHash import MinHash\n",
    "\n",
    "\n",
    "\n",
    "clustering_names = [\n",
    "    'SpectralClustering', 'MinHashSpectralClustering', 'DBSCAN', 'MinHashDBSCAN']\n",
    "\n",
    "# original algorithms\n",
    "spectral = cluster.SpectralClustering(n_clusters=2, eigen_solver='arpack',\n",
    "                                      affinity=\"nearest_neighbors\", n_neighbors=10)\n",
    "dbscan = cluster.DBSCAN(eps=.2, metric=\"euclidean\")\n",
    "\n",
    "# objects used for algorithms with precomputed minHash\n",
    "minHash0 = MinHash(n_neighbors=10)\n",
    "minHash1 = MinHash(n_neighbors=10)\n",
    "\n",
    "spectralMinHash = cluster.SpectralClustering(n_clusters=2, eigen_solver='arpack',\n",
    "                                      affinity=\"precomputed\", n_neighbors=10)\n",
    "\n",
    "dbscanMinHash = cluster.DBSCAN(eps=.2, metric='precomputed')\n",
    "\n",
    "\n",
    "minHashClusteringSpectralClustering = MinHashClustering(minHash0, spectralMinHash)\n",
    "minHashClusteringDBSCAN = MinHashClustering(minHash1, dbscanMinHash)\n",
    "\n",
    "clustering_algorithms=[spectral, minHashClusteringSpectralClustering, dbscan, minHashClusteringDBSCAN]\n",
    "    \n",
    "X = data_sparse\n",
    "for name, algorithm in zip(clustering_names, clustering_algorithms):\n",
    "    t0 = time.time()\n",
    "    y_pred = algorithm.fit_predict(X)\n",
    "    t1 = time.time()\n",
    "    y_pred = y_pred.astype(np.int)\n",
    "    print name, \":\\t\", float(\"{0:.2f}\".format(adjusted_rand_score(y_true, y_pred))), \"\\t\\tComputation time: \", t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
